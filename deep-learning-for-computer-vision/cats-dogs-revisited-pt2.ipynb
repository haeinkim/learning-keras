{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using a pre-trained convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Instantiating the VGG16 convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Displaying a summary of the convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1.3 Extracting features using the pre-trained convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './data/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape= (sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape= (sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory, \n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop\n",
    "            # we must 'break' after every image has been seen once.\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.4655 - acc: 0.7750 - val_loss: 0.3131 - val_acc: 0.8670\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.2932 - acc: 0.8685 - val_loss: 0.2591 - val_acc: 0.8930\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.2365 - acc: 0.9030 - val_loss: 0.2698 - val_acc: 0.8930\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.2091 - acc: 0.9160 - val_loss: 0.2439 - val_acc: 0.9030\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.1760 - acc: 0.9330 - val_loss: 0.2366 - val_acc: 0.9050\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.1584 - acc: 0.9380 - val_loss: 0.2477 - val_acc: 0.9000\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.1362 - acc: 0.9540 - val_loss: 0.2480 - val_acc: 0.9010\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.1244 - acc: 0.9560 - val_loss: 0.2431 - val_acc: 0.9050\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.1127 - acc: 0.9630 - val_loss: 0.2718 - val_acc: 0.8900\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0920 - acc: 0.9645 - val_loss: 0.2476 - val_acc: 0.9060\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0923 - acc: 0.9625 - val_loss: 0.2542 - val_acc: 0.9010\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0808 - acc: 0.9690 - val_loss: 0.2843 - val_acc: 0.8940\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0678 - acc: 0.9780 - val_loss: 0.2721 - val_acc: 0.9020\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0579 - acc: 0.9815 - val_loss: 0.2797 - val_acc: 0.9030\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0523 - acc: 0.9835 - val_loss: 0.2790 - val_acc: 0.9070\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0455 - acc: 0.9885 - val_loss: 0.3303 - val_acc: 0.8960\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0393 - acc: 0.9890 - val_loss: 0.2929 - val_acc: 0.9020\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0376 - acc: 0.9895 - val_loss: 0.3005 - val_acc: 0.9010\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0321 - acc: 0.9915 - val_loss: 0.3601 - val_acc: 0.8840\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0273 - acc: 0.9930 - val_loss: 0.3236 - val_acc: 0.8990\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0237 - acc: 0.9950 - val_loss: 0.3302 - val_acc: 0.8980\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0226 - acc: 0.9945 - val_loss: 0.3339 - val_acc: 0.9010\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0175 - acc: 0.9985 - val_loss: 0.3438 - val_acc: 0.9010\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0163 - acc: 0.9960 - val_loss: 0.3676 - val_acc: 0.8920\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0140 - acc: 0.9980 - val_loss: 0.3858 - val_acc: 0.8970\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0146 - acc: 0.9960 - val_loss: 0.3943 - val_acc: 0.8980\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0120 - acc: 0.9980 - val_loss: 0.3831 - val_acc: 0.9040\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0091 - acc: 0.9995 - val_loss: 0.3801 - val_acc: 0.9020\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0078 - acc: 0.9990 - val_loss: 0.4777 - val_acc: 0.8880\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 1s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4040 - val_acc: 0.9040\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30, \n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Plotting our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niGSMAr+ISMYo8IuIZMz/B7DYdCOPzUmhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ee8c0af470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nalCJ7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ee86722cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Adding a densely-connected classifier on top of the convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Summary of the extended model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base:  30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base: ', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base:  4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base: ', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7 Training the model end-to-end with a frozen convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 75s - loss: 0.4661 - acc: 0.7875 - val_loss: 0.2384 - val_acc: 0.9020\n",
      "Epoch 2/50\n",
      " 43/100 [===========>..................] - ETA: 37s - loss: 0.3594 - acc: 0.8221"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ead167edfaec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     validation_steps=50)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1115\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.8 Plotting our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
